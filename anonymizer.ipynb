{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-md==3.4.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl in ./venv/lib/python3.7/site-packages (3.4.1)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in ./venv/lib/python3.7/site-packages (from en-core-web-md==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (47.1.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\" in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv/lib/python3.7/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in ./venv/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.7/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in ./venv/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.11.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./venv/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./venv/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./venv/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/Users/dominik/Documents/Masterarbeit-Code/nlp-satisfaction/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "!python -m spacy download en_core_web_md\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dataframe\n",
    "filelocation = 'data/DataClean'\n",
    "df = pd.read_feather(filelocation)\n",
    "#df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Kommentar\"].notnull()]\n",
    "df = df[[\"participant_id\",\"Kommentar\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Kommentar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41305</td>\n",
       "      <td>Habe schon mehrmals erlebt, dass es im Speisew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41334</td>\n",
       "      <td>Ansteben, dass auch in gut frequentierte perip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41459</td>\n",
       "      <td>Die 1. Klasse muss deutluch aufgewertet werden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41497</td>\n",
       "      <td>Bessere (neue!) Züge in der Westschweiz!!! Län...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id                                          Kommentar\n",
       "5            41305  Habe schon mehrmals erlebt, dass es im Speisew...\n",
       "6            41334  Ansteben, dass auch in gut frequentierte perip...\n",
       "9            41459  Die 1. Klasse muss deutluch aufgewertet werden...\n",
       "10           41497  Bessere (neue!) Züge in der Westschweiz!!! Län..."
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a small test df by hand\n",
    "#d = {'id': [1, 2,3,4,5,6], 'Kommentar': [\"hallo mein Name ist Dominik und meine email dominik@web.de\", \"meldet euch +41 79 290 53 02\",\"keine info\",\"Der Zugbegleiter Felix Böwing war sehr unfreundlich\",\"Die SBB hat es mal wieder verkackt\",\" Bitte überweisen sie das Geld an AL35202111090000000001234567\"]}\n",
    "#df  = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymizer_de(list):\n",
    "    \"\"\"\n",
    "    Anonymize a list of text comments.\n",
    "    \n",
    "    This function uses a natural language processing (NLP) engine and an anonymizer engine to identify and anonymize personal information in a list of text comments. The function supports German language comments, and can recognize entities such as person names, email addresses, phone numbers, credit card numbers, and IBAN codes.\n",
    "    \n",
    "    Args:\n",
    "        list: A list of strings containing text comments to be anonymized.\n",
    "    \n",
    "    Returns:\n",
    "        A list of strings containing the anonymized text comments.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    #Create configuration containing engine name and models\n",
    "    configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [{\"lang_code\": \"de\", \"model_name\": \"de_core_news_lg\"}],}\n",
    "    \n",
    "    # Create NLP engine based on configuration\n",
    "    provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "    nlp_engine = provider.create_engine()\n",
    "    \n",
    "    # the languages are needed to load country-specific recognizers \n",
    "    # # for finding phones, passport numbers, etc.\n",
    "    analyzer = AnalyzerEngine(nlp_engine=nlp_engine,\n",
    "                              supported_languages=[\"de\"])\n",
    "\n",
    "    # Create the anonymizer\n",
    "    anonymizer = AnonymizerEngine()\n",
    "\n",
    "    # Anonymize each comment in the list\n",
    "    anonymized_text_list = [\n",
    "        anonymizer.anonymize(text=comment,\n",
    "                             analyzer_results=analyzer.analyze(text=comment,\n",
    "                                                              language='de',\n",
    "                                                              entities=[\"PERSON\",\"EMAIL_ADDRESS\",\"PHONE_NUMBER\",\"CREDIT_CARD\",\"IBAN_CODE\"])).text\n",
    "        if isinstance(comment, str) else None\n",
    "        for comment in list\n",
    "    ]\n",
    "    \n",
    "    return anonymized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extract_ner_entities_list(lst, entitie):\n",
    "    \"\"\"\n",
    "    Find and extract named entities from a list of strings using natural language processing.\n",
    "    \n",
    "    This function uses a specified NLP engine and language model to detect named entities in a list of strings,\n",
    "    and returns a list of the detected entities. If the input is not a string, None is returned instead.\n",
    "    \n",
    "    Args:\n",
    "        lst: A list of strings to process.\n",
    "        entitie: The named entity type to look for (e.g. \"person\", \"organization\", \"location\", etc.)\n",
    "        \n",
    "    Returns:\n",
    "        A list of detected entities, or None if the input is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create configuration containing engine name and models\n",
    "    configuration = {\n",
    "        \"nlp_engine_name\": \"spacy\",\n",
    "        \"models\": [{\"lang_code\": \"de\", \"model_name\": \"de_core_news_lg\"}],\n",
    "    }\n",
    "    \n",
    "    # Create NLP engine based on configuration\n",
    "    provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "    nlp_engine = provider.create_engine()\n",
    "    \n",
    "    # the languages are needed to load country-specific recognizers \n",
    "    # # for finding phones, passport numbers, etc.\n",
    "    analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=[\"de\"])\n",
    "    \n",
    "    # Create a list comprehension that processes each string in the input list and\n",
    "    # appends the detected entities to the results list. If the input is not a string,\n",
    "    # None is appended to the results list.\n",
    "    results_list = [\n",
    "        None if not isinstance(comment, str)\n",
    "        else [(comment[res.start:res.end]) for res in analyzer.analyze(text=comment, language=\"de\", entities=[entitie])]\n",
    "        for comment in lst\n",
    "    ]\n",
    "\n",
    "    # Replace empty lists in the results list with None.\n",
    "    results_list = [None if not x else x for x in results_list]\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column_values(df, col1, col2):\n",
    "    # Check if either of the two columns contains a non-null value\n",
    "    result = (df[col1].notnull() | df[col2].notnull()).tolist()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anonimize Kommentare as new column\n",
    "df[\"Kommentar_anonymised\"] = anonymizer_de(df.Kommentar)\n",
    "\n",
    "# Add Phone number and email as new column\n",
    "df[\"email_address\"]=find_extract_ner_entities_list(df.Kommentar, \"EMAIL_ADDRESS\")\n",
    "df[\"phone_number\"]=find_extract_ner_entities_list(df.Kommentar, \"PHONE_NUMBER\")\n",
    "\n",
    "\n",
    "# Add personal information column (TRUE or FALSE)\n",
    "df[\"has_contact_details\"]=check_column_values(df,'phone_number','email_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anomnymisation_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5379947b43a70a4869f96bb5b4ea26a56779d5ba35c9ca75314741dcfc42fccf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
